{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aketu\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194 entries, 0 to 193\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0                     194 non-null int64\n",
      "sentence                       194 non-null object\n",
      "support_keyword                194 non-null int64\n",
      "after_conclusion_keyword       194 non-null int64\n",
      "previous_conclusion_keyword    194 non-null int64\n",
      "support_sentence               194 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 9.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"pandas_label.csv\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    138\n",
      "1     56\n",
      "Name: support_sentence, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"support_sentence\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target/input split\n",
    "y = df[\"support_sentence\"]\n",
    "X = df.drop([\"Unnamed: 0\", \"sentence\", \"support_sentence\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aketu\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# setting random state\n",
    "rs = 10\n",
    "\n",
    "X_mat = X.as_matrix()\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X_mat, y, test_size=0.2, stratify=y, random_state=rs)\n",
    "\n",
    "smt=SMOTE(random_state=20);\n",
    "X_train2, Y_train2=smt.fit_sample(x_train2,y_train2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    110\n",
      "0    110\n",
      "dtype: int64\n",
      "0    28\n",
      "1    11\n",
      "Name: support_sentence, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (pd.Series(Y_train2).value_counts())\n",
    "print (pd.Series(y_test2).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling\n",
      "-------------\n",
      "Variable #0: min 0, max 1, mean 0.25 and std dev 0.44\n",
      "Variable #1: min 0, max 2, mean 0.09 and std dev 0.30\n",
      "Variable #2: min 0, max 2, mean 0.09 and std dev 0.30\n",
      "After scaling\n",
      "-------------\n",
      "Variable #0: min -0.5843487097907777, max 1.711306935815849, mean 0.00 and std dev 1.00\n",
      "Variable #1: min -0.3001501125938318, max 6.303152364470468, mean -0.00 and std dev 1.00\n",
      "Variable #2: min -0.30015011259383223, max 6.303152364470477, mean -0.00 and std dev 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# initialise a standard scaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# visualise min, max, mean and standard dev of data before scaling\n",
    "print(\"Before scaling\\n-------------\")\n",
    "for i in range(3):\n",
    "    col = X_train2[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".\n",
    "          format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "# learn the mean and std.dev of variables from training data\n",
    "# then use the learned values to transform training data\n",
    "X_train2 = scaler.fit_transform(X_train2, Y_train2)\n",
    "\n",
    "print(\"After scaling\\n-------------\")\n",
    "for i in range(3):\n",
    "    col = X_train2[:,i]\n",
    "    print(\"Variable #{}: min {}, max {}, mean {:.2f} and std dev {:.2f}\".\n",
    "          format(i, min(col), max(col), np.mean(col), np.std(col)))\n",
    "\n",
    "x_test2 = scaler.transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aketu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=10, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelLR = LogisticRegression(random_state=rs)\n",
    "\n",
    "#cv_average_score=cross_val_score(model, X_train, y_train, cv=10)\n",
    "# fit it to training data\n",
    "\n",
    "modelLR.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7863636363636364\n",
      "Test accuracy: 0.8205128205128205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87        28\n",
      "           1       0.67      0.73      0.70        11\n",
      "\n",
      "    accuracy                           0.82        39\n",
      "   macro avg       0.78      0.79      0.78        39\n",
      "weighted avg       0.83      0.82      0.82        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training and test accuracy\n",
    "print(\"Train accuracy:\", modelLR.score(X_train2, Y_train2))\n",
    "print(\"Test accuracy:\", modelLR.score(x_test2, y_test2))\n",
    "#print(\"Crossvalidation accuracy\",np.mean(cv_average_score))\n",
    "# classification report on test data\n",
    "y_pred2 = modelLR.predict(x_test2)\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0 0 0 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0]\n",
      "[1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test2.values)\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support_keyword : 1.7943796812255421\n",
      "after_conclusion_keyword : 0.566373130328095\n",
      "previous_conclusion_keyword : 0.3007514307115342\n"
     ]
    }
   ],
   "source": [
    "feature_names=X.columns\n",
    "coef=modelLR.coef_[0]\n",
    "\n",
    "indices = np.argsort(np.absolute(coef))\n",
    "indices = np.flip(indices, axis=0)\n",
    "\n",
    "indices=indices[:20]\n",
    "\n",
    "for i in indices:\n",
    "    print(feature_names[i], \":\", coef[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aketu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params2 = {'C': [pow(10, x) for x in range(-6, 10)]}\n",
    "\n",
    "# use all cores to tune logistic regression with C parameter\n",
    "cv = GridSearchCV(param_grid=params2, estimator=LogisticRegression(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv.fit(X_train2, Y_train2)\n",
    "\n",
    "# print parameters of the best model\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7772727272727272\n",
      "Test accuracy: 0.8717948717948718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91        28\n",
      "           1       0.80      0.73      0.76        11\n",
      "\n",
      "    accuracy                           0.87        39\n",
      "   macro avg       0.85      0.83      0.84        39\n",
      "weighted avg       0.87      0.87      0.87        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test the best model\n",
    "print(\"Train accuracy:\", cv.score(X_train2, Y_train2))\n",
    "print(\"Test accuracy:\", cv.score(x_test2, y_test2))\n",
    "\n",
    "y_pred2 = cv.predict(x_test2)\n",
    "print(classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.47555353 1.03045801 0.33802345]]\n"
     ]
    }
   ],
   "source": [
    "print(modelLR.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
